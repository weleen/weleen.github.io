<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="weleen's blog"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>Object Tracking: A Survey | Welcome to weleen's blog</title><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Object Tracking: A Survey</h1><a id="logo" href="/.">Welcome to weleen's blog</a><p class="description">Pursue myself</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="search"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Object Tracking: A Survey</h1><div class="post-meta"><a href="/2016/06/05/Object-Tracking-A-Survey/#comments" class="comment-count"><i data-disqus-identifier="2016/06/05/Object-Tracking-A-Survey/" class="disqus-comment-count"></i>Guestbook</a><p><span class="date">Jun 05, 2016</span><span><a href="/categories/Computer-Science/" class="category">Computer Science</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Hits</i></i></span></p></div><div class="post-content"><p>这篇文章是一篇经典的有关目标跟踪的review paper，由于最近在看相关的文献，把这篇文章找出来看一看，顺便写写相关的总结。<br><a href="http://delivery.acm.org/10.1145/1180000/1177355/a13-yilmaz.pdf?ip=222.205.106.54&id=1177355&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E0E9E463C2E5391F8%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=772807738&CFTOKEN=28997377&__acm__=1465105166_0f184b5770d0d9486b68284137e5957c" target="_blank" rel="noopener">download</a></p>
<a id="more"></a>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>目标跟踪是计算机视觉领域重要的一个任务，在视频分析中有三个重要步骤：感兴趣的运动物体检测，运动物体的跟踪以及根据运动分析行为。目标跟踪的应用点有基于运动的目标识别，智能监控，视频索引，人机交互，交通监控，车辆导航。</p>
<p>目标跟踪问题面临的挑战包括：3D物体向2D投影的信息损失，图像噪声，目标运动复杂，非刚性物体的跟踪，目标会出现遮挡，目标形状复杂，场景光照变换以及实时跟踪的需求。</p>
<p>目标跟踪问题一般都会有一定的假设来简化问题，比如假设目标运动是平滑的或者加速运动是均匀的，或者目标的数量是确定的。</p>
<h2 id="Object-Representation"><a href="#Object-Representation" class="headerlink" title="Object Representation"></a>Object Representation</h2><p>目标表示形式有很多种：</p>
<h3 id="Shape-Representations"><a href="#Shape-Representations" class="headerlink" title="Shape Representations"></a>Shape Representations</h3><ol>
<li><strong>点</strong>，把目标表示成一个点或者一系列点，这种方法适用于跟踪小范围的目标。</li>
<li><strong>几何形状</strong>， 把目标表示成一个长方形或者是椭圆等等，这种时候，目标运动就可以表示成这种几何形状的平移、旋转、仿射变换等等。这种表示方式适合简单的刚性物体，也可以用于跟踪非刚性物体。</li>
<li><strong>目标的轮廓</strong>，用目标轮廓来确定目标的范围，在轮廓内部的称为目标的剪影，这种表示方法适合于简单的非刚性物体。</li>
<li><strong>铰链式的形状模型</strong>，通过把目标分成一个个部分，连接各个部分来表示一个目标，比如人体就可以分成头、胳膊、手掌、脚等部分，而各个部分之间通过运动模型来相互关联。</li>
<li><strong>骨骼模型</strong>，目标的骨骼模型可以用于建模有关节的和刚性目标。</li>
</ol>
<p><img src="/img/Object-Tracking-A-Survey/1.png" alt="Object representation"></p>
<h3 id="Appearance-Representations"><a href="#Appearance-Representations" class="headerlink" title="Appearance Representations"></a>Appearance Representations</h3><ol>
<li><strong>Probability densities of object appearance</strong>，The probability densities of object appearance features (color, texture) can be computed from the image regions specified by the shape models (interior region of an ellipse or a contour).</li>
<li><strong>Template</strong>，用简单的几何形状或者是剪影合成Template，但是Template只适合目标姿势变化不是很大的情况。</li>
<li><strong>Active appearance models</strong>, 对目标形状和外观同时建模可以得到Activce appaerance models， 目标的形状一般是a set of landmarks，对于每一个landmark，表示成颜色、纹理或是梯度的一个向量。</li>
<li><strong>Multiview appearance models</strong>，组合多个角度的目标信息。 One approach is to generate a subspace from the given views， 可以通过PCA和ICA实现。 Another approach is by training a set of classifiers。</li>
</ol>
<h2 id="Feature-selection-for-tracking"><a href="#Feature-selection-for-tracking" class="headerlink" title="Feature selection for tracking"></a>Feature selection for tracking</h2><p>最佳的特征是可以将目标很容易分辨出来的特征，特征选择和目标的表示密切相关，例如在使用直方图表示目标时，一般使用颜色特征；在使用目标的轮廓来表示目标时，一般使用目标的角点来作为特征。</p>
<ol>
<li><strong>颜色</strong>， 有RGB、LUV、LAB、HSV等颜色空间可以选择，但是颜色特征比较容易受到噪声影响。</li>
<li><strong>边</strong>，边的一个重要性质就是不易受到光照变化的影响，而且比较容易实现。</li>
<li><strong>光流</strong>，光流假定光照不变，定义了区域内每个像素的位移量。一般光流用在分割和跟踪问题中。</li>
<li><strong>纹理</strong>，纹理用来表示物体表面的平滑性和规则性。和颜色特征相比，产生纹理特征需要多一步处理的过程。和边特征类似，纹理特征也对光照变化比较鲁棒。</li>
</ol>
<h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><p>目标跟踪需要一个目标检测工具，一般的目标检测算法使用单帧中的信息，也有一些算法使用时间信息来减少错误检测，比如计算连续帧之间的差值，在连续的帧之中高亮那些变化的区域。</p>
<h3 id="Point-Detectors"><a href="#Point-Detectors" class="headerlink" title="Point Detectors"></a>Point Detectors</h3><p>点检测器有Harris、KLT、SIFT等。一篇关于点检测器的论文<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1498756" target="_blank" rel="noopener">A Performance Evaluation of Local Descriptors</a>。<br>Harris角点用了一阶微分作为特征$(I_x,I_y)$，用下面的式子表示一个pixel的值。<br><img src="/img/Object-Tracking-A-Survey/2.png" alt="Harris"><br>详细的Harris角点的资料可以在网上找找。<br>还有KLT角点和SIFT角点也很常用。</p>
<h3 id="Background-Subtraction"><a href="#Background-Subtraction" class="headerlink" title="Background Subtraction"></a>Background Subtraction</h3><p>背景减除的过程描述：建立背景模型，对于每帧计算偏差，变化较大的区域就是移动的目标。<br><img src="/img/Object-Tracking-A-Survey/3.png" alt="Background Subtraction"><br>可以用GMM对每个像素点建模，分离前景和背景。还可以结合其他信息，比如纹理信息，以应对光照变换等情况。还有使用HMM建模，用特征值分解等方法。以上的这些方法都是针对静止背景的。对于Time-vary background，有一种ARMA的模型可以用来解决。</p>
<h3 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a>Segmentation</h3><p>分割的任务是把图片分成一些类似的区域。对分割算法，最重要的是分割结果的评价和分割的方法。</p>
<h4 id="Mean-shift-Clustering"><a href="#Mean-shift-Clustering" class="headerlink" title="Mean-shift Clustering"></a>Mean-shift Clustering</h4><p>用mean-shift分割的思想来进行tracking。<br><img src="/img/Object-Tracking-A-Survey/4.png" alt="Mean-shift"></p>
<h4 id="Image-Segmentation-Using-Graph-Cuts"><a href="#Image-Segmentation-Using-Graph-Cuts" class="headerlink" title="Image Segmentation Using Graph-Cuts"></a>Image Segmentation Using Graph-Cuts</h4><p>用过minimum cut来做segmentation，graph的weight是根据color similarity决定的<br>，这个方法的问题在于可能出现oversegmentation， Normailized cut可以解决这个问题。</p>
<h4 id="Active-Contour"><a href="#Active-Contour" class="headerlink" title="Active Contour"></a>Active Contour</h4><p>对一个能量函数的优化得到目标区域的轮廓。<br><img src="/img/Object-Tracking-A-Survey/5.png" alt="Active Contour"></p>
<h3 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h3><p>用监督学习的方式学习分类器，将目标和非目标的物体分离开，有很多样的方法，神经网络、决策树、adaboost、SVM等。对于数据那个小的问题，可以用联合学习的方式解决。文章详细介绍了adaboost和SVM。</p>
<h2 id="Object-Tracking"><a href="#Object-Tracking" class="headerlink" title="Object Tracking"></a>Object Tracking</h2><p><img src="/img/Object-Tracking-A-Survey/6.png" alt="Object Tracking taxonomy"></p>
<ol>
<li>Point　Tracking，目标用点表示，这种方法需要另外的检测方法。</li>
<li>Kernel Tracking，Kernel refers to the object shape and appearance。目标跟踪一般通过带参的形变，比如平移、旋转和仿射变换。</li>
<li>Silhouette Tracking，估计目标区域来进行跟踪，一般用区域内的信息，表示形式有appearance density和shape models。</li>
</ol>
<h3 id="Point-Tracking-Methods"><a href="#Point-Tracking-Methods" class="headerlink" title="Point Tracking Methods"></a>Point Tracking Methods</h3><p><img src="/img/Object-Tracking-A-Survey/8.png" alt="Point Tracking Methods"></p>
<h3 id="Kernel-Tracking"><a href="#Kernel-Tracking" class="headerlink" title="Kernel Tracking"></a>Kernel Tracking</h3><p>inlcude two subcategories: templates and density-based appearance models, and multiview appearance models.</p>
<h4 id="Tracking-Using-Template-and-Density-Based-Appearance-Models"><a href="#Tracking-Using-Template-and-Density-Based-Appearance-Models" class="headerlink" title="Tracking Using Template and Density-Based Appearance Models"></a>Tracking Using Template and Density-Based Appearance Models</h4><ul>
<li>single object, 1)template matching, a brute force search method.由于搜索代价比较大，所以一般搜索空间限定在上一帧位置附近。2）mean-shift。3）多个模块结合的跟踪器。4）光流法。</li>
<li>multiple objects, 1)Tao et al. [2002] propose an object tracking method based on modeling the whole image as a set of layers。为整个图像建立多层模型，背景和各个目标都有自己的模型。2）Isard and MacCormick [2001] propose joint modeling of the background and foreground regions for tracking，用混合高斯模型作为前景和背景的模型。</li>
</ul>
<h4 id="Tracking-Using-MultiviewAppearance-Models"><a href="#Tracking-Using-MultiviewAppearance-Models" class="headerlink" title="Tracking Using MultiviewAppearance Models"></a>Tracking Using MultiviewAppearance Models</h4><p>上面的方法是用直方图、templates这样的模型来表示目标，在相邻帧之间如果出现比较大的变化，模型可能就不可靠了。使用离线学习的multiview的模型可以克服这个缺点。<br>文章举了两个例子，一种方法是用PCA，一种是用SVM。</p>
<p><img src="/img/Object-Tracking-A-Survey/9.png" alt="Kernel Tracking Methods"></p>
<h3 id="Silhouette-Tracking"><a href="#Silhouette-Tracking" class="headerlink" title="Silhouette Tracking"></a>Silhouette Tracking</h3><p>不能用一般的形状表示的物体，可以用Silhouette来精确刻画。可以把Silhouette tracking分为shape matching approaches和contour tracking approaches。</p>
</div><div class="post-copyright"><blockquote><p>Original author: weleen</p><p>Original link: <a href="http://weleen.github.io/2016/06/05/Object-Tracking-A-Survey/">http://weleen.github.io/2016/06/05/Object-Tracking-A-Survey/</a></p><p>Copyright Notice: Please indicate the source of the reprint (must retain the author's signature and link)</p></blockquote></div><div class="tags"><a href="/tags/Object-Tracking/">Object Tracking</a></div><div class="post-share"><div class="social-share"><span>Share:</span></div></div><div class="post-nav"><a href="/2016/06/13/Online-Object-Tracking-A-Benchmark/" class="pre">Online Object Tracking: A Benchmark</a><a href="/2016/05/31/A-Survey-of-Appearance-Models-in-Visual-Object-Tracking/" class="next">A Survey of Appearance Models in Visual Object Tracking</a></div><div id="comments"><div id="disqus_thread"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Contents</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Representation"><span class="toc-text">Object Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Shape-Representations"><span class="toc-text">Shape Representations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Appearance-Representations"><span class="toc-text">Appearance Representations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature-selection-for-tracking"><span class="toc-text">Feature selection for tracking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Detection"><span class="toc-text">Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Point-Detectors"><span class="toc-text">Point Detectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Background-Subtraction"><span class="toc-text">Background Subtraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Segmentation"><span class="toc-text">Segmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Mean-shift-Clustering"><span class="toc-text">Mean-shift Clustering</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-Segmentation-Using-Graph-Cuts"><span class="toc-text">Image Segmentation Using Graph-Cuts</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Active-Contour"><span class="toc-text">Active Contour</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Supervised-Learning"><span class="toc-text">Supervised Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Tracking"><span class="toc-text">Object Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Point-Tracking-Methods"><span class="toc-text">Point Tracking Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kernel-Tracking"><span class="toc-text">Kernel Tracking</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Tracking-Using-Template-and-Density-Based-Appearance-Models"><span class="toc-text">Tracking Using Template and Density-Based Appearance Models</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tracking-Using-MultiviewAppearance-Models"><span class="toc-text">Tracking Using MultiviewAppearance Models</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Silhouette-Tracking"><span class="toc-text">Silhouette Tracking</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/11/26/Bit-Scalable-Deep-Hashing-With-Regularized-Similarity-Learning-for-Image-Retrieval-and-Person-Re-Identification/">Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Supervised-Hashing-for-Image-Retrieval-via-Image-Representation-Learning/">Supervised Hashing for Image Retrieval via Image Representation Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Simultaneous-Feature-Learning-and-Hash-Coding-with-Deep-Neural-Networks/">Simultaneous Feature Learning and Hash Coding with Deep Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/21/awesome-hash/">awesome-hash</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/09/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%90%86%E8%A7%A3/">最大熵模型的理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/21/Unsupervised-Cross-dataset-Person-Re-identification-by-Transfer-Learning-of-Spatial-Temporal-Pattern/">Unsupervised Cross-dataset Person Re-identification by Transfer Learning of Spatial-Temporal Pattern</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/12/Self-similarity-Grouping-A-Simple-Unsupervised-Cross-Domain-Adaptation-Approach-for-Person-Re-identification/">Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation Approach for Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/">STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/Cross-view-Asymmetric-Metric-Learning-for-Unsupervised-Person-Re-identification/">Cross-view Asymmetric Metric Learning for Unsupervised Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/24/awesome-reid/">awesome-reid</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/">Computer Science</a><span class="category-list-count">17</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/Collections/">Collections</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"><a href="/tags/ReID/" style="font-size: 15px;">ReID</a> <a href="/tags/Unsupervised/" style="font-size: 15px;">Unsupervised</a> <a href="/tags/Cross-view/" style="font-size: 15px;">Cross-view</a> <a href="/tags/Metric-Learning/" style="font-size: 15px;">Metric Learning</a> <a href="/tags/Object-Tracking/" style="font-size: 15px;">Object Tracking</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;"> Deep Hash</a> <a href="/tags/DNN/" style="font-size: 15px;">DNN</a> <a href="/tags/Hard-Negtive-Mining/" style="font-size: 15px;">Hard Negtive Mining</a> <a href="/tags/Hand-Pose-Estimation/" style="font-size: 15px;">Hand Pose Estimation</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Video-Person-ReID/" style="font-size: 15px;">Video Person ReID</a> <a href="/tags/Attention/" style="font-size: 15px;">Attention</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;">Deep Hash</a> <a href="/tags/Grouping/" style="font-size: 15px;">Grouping</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/Unsupervised-ReID/" style="font-size: 15px;">Unsupervised ReID</a> <a href="/tags/Transfer-Learning/" style="font-size: 15px;">Transfer Learning</a> <a href="/tags/hash/" style="font-size: 15px;">hash</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/" style="font-size: 15px;">最大熵</a> <a href="/tags/%E7%86%B5/" style="font-size: 15px;">熵</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archive</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/">2016</a><span class="archive-list-count">7</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Site Map</a> |  <a href="/atom.xml">Subscribe to this site</a> |  <a href="/about/">Contact the blogger</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">weleen.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-101752082-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.4" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>var disqus_shortname = 'https-weleen-github-io';
var disqus_identifier = '2016/06/05/Object-Tracking-A-Survey/';
var disqus_title = 'Object Tracking: A Survey';
var disqus_url = 'http://weleen.github.io/2016/06/05/Object-Tracking-A-Survey/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//https-weleen-github-io.disqus.com/count.js" async></script><script type="text/javascript" src="//https-weleen-github-io.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></body></html>