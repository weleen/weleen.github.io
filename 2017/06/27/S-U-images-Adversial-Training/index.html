<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="weleen's blog"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>S+U images Adversial Training | Welcome to weleen's blog</title><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">S+U images Adversial Training</h1><a id="logo" href="/.">Welcome to weleen's blog</a><p class="description">Pursue myself</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="search"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">S+U images Adversial Training</h1><div class="post-meta"><a href="/2017/06/27/S-U-images-Adversial-Training/#comments" class="comment-count"><i data-disqus-identifier="2017/06/27/S-U-images-Adversial-Training/" class="disqus-comment-count"></i>Guestbook</a><p><span class="date">Jun 27, 2017</span><span><a href="/categories/Computer-Science/" class="category">Computer Science</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Hits</i></i></span></p></div><div class="post-content"><p>CVPR2017论文 <strong>Learning from Simulated and Unsupervised Images through Adversarial Training</strong></p>
<a id="more"></a>
<p>文章主要提出的几个新idea：</p>
<ul>
<li>用无标签的图像以及合成图像进行学习，让图像更真实</li>
<li>训练一个refine网络对合成图像进行对抗学习</li>
<li>对GAN进行了一些修改，让训练更稳定，主要是后文提到的history和local patch</li>
</ul>
<h2 id="S-U-Learning"><a href="#S-U-Learning" class="headerlink" title="S+U Learning"></a>S+U Learning</h2><p><img src="/img/S-U-images-Adversial-Training/architecture.png" alt="architecture"></p>
<p>整个框架还是沿用的GAN的架构，<br>G网络：用simulator合成的图像作为refine network的输入。<br>D网络：把前面的refine network的输出和unlabelled图片作为输入，输出判别是真是图片还是虚假图片。</p>
<p>G网络的loss在GAN的基础上增加了一个regularization loss，主要是因为G网络的输入是带标签的合成数据（比如使用的gaze image，是有gaze direction的，而整个实验最后还是为了用来提高监督学习的效果）。loss表示成<br>$$L_R(\theta) = \sum_{i} l_{real}(\theta; \hat{x}<em>i, y) + \lambda l</em>{reg}(\theta;\hat{x}<em>i, x_i)$$<br>，其中第一项loss是对抗loss，即$l</em>{real}(\theta;\hat{x}<em>i,y)=-\sum{log(1-D</em>{\phi}(R_{\theta}(x_i)))}$，$D_{\phi}$是判别器的输出，表示图片是合成图片的概率，可以发现这个loss越小，那么合成图像越难以分辨（$1-D_{\phi}(R_{\theta}(x_i))$越大）。$ l_{reg}=||R_{\theta}(x_i)-x_i||_1 $使得输入和输出相似。而判别器的loss就是GAN的loss，这里就不写出来了。</p>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p>主要的改进点在最开始的地方已经写过了，一个是local patch，一个是history，下面分别介绍。</p>
<h3 id="local-patch-adversarial-loss"><a href="#local-patch-adversarial-loss" class="headerlink" title="local patch adversarial loss"></a>local patch adversarial loss</h3><p>因为GAN在训练的时候会出现artifacts的情况，具体来说就是图片没有意义，但是loss很小，原因应该是学习的feature是判别器不容易判别的feature。讲artifects的文章可以看看<a href="http://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">distill</a>。为了解决这个问题，作者提出用local patch作为单位（对判别器而言），对原始图像最后卷积成w x h的图像，w和h是图像被分成的patch大小，然后判别器的对抗loss变成交叉熵loss的和(The adversarial loss function is the sum of the cross-entropy losses over the local patches. 这段看原文可能更清楚一点)。</p>
<h3 id="history"><a href="#history" class="headerlink" title="history"></a>history</h3><p>这个方法主要是为了应对两个问题：</p>
<ol>
<li>在对抗学习过程中，因为不同的训练样本服从的分布还是有区别的，如果仅仅使用refine network最近的输出作为输入，那么容易出现divergency。</li>
<li>refine network可能会产生判别器遗忘的artifects。<br>第一个问题，我认为不解决的话需要调超参，比较麻烦，但是通过引入历史的refined images能提高多少，我觉得效果应该也不会很好，毕竟合成图像也是随机生成的。<br>第二个问题应该能够有很大的改善。<br>具体实现就是保存一个refined images的池，在每次训练判别器的时候，minibatch输入有一部分是从池中选取，一部分是G网络产生。</li>
</ol>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验用了两个数据集，一个是MPIIGaze，一个NYU Hand。<br>先是展示了一下生成器生成图像的真实性，用了一个表还有几张图片，可以看出生成图片还是很逼真的。<br><img src="/img/S-U-images-Adversial-Training/table_for_generator.png" alt="table for generator"><br><img src="/img/S-U-images-Adversial-Training/gaze_simulated_history.png" alt="gaze simulated history"></p>
<p>具体实验结果就不放了，大家可以直接去看论文。</p>
</div><div class="post-copyright"><blockquote><p>Original author: weleen</p><p>Original link: <a href="http://weleen.github.io/2017/06/27/S-U-images-Adversial-Training/">http://weleen.github.io/2017/06/27/S-U-images-Adversial-Training/</a></p><p>Copyright Notice: Please indicate the source of the reprint (must retain the author's signature and link)</p></blockquote></div><div class="tags"><a href="/tags/GAN/">GAN</a></div><div class="post-share"><div class="social-share"><span>Share:</span></div></div><div class="post-nav"><a href="/2019/07/24/awesome-reid/" class="pre">awesome-reid</a><a href="/2016/08/18/Bootstrapping-Face-Detection-with-Hard-Negtive-Examples/" class="next">Bootstrapping Face Detection with Hard Negtive Examples</a></div><div id="comments"><div id="disqus_thread"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Contents</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#S-U-Learning"><span class="toc-text">S+U Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#改进"><span class="toc-text">改进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#local-patch-adversarial-loss"><span class="toc-text">local patch adversarial loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#history"><span class="toc-text">history</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验"><span class="toc-text">实验</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/11/26/Bit-Scalable-Deep-Hashing-With-Regularized-Similarity-Learning-for-Image-Retrieval-and-Person-Re-Identification/">Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Supervised-Hashing-for-Image-Retrieval-via-Image-Representation-Learning/">Supervised Hashing for Image Retrieval via Image Representation Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Simultaneous-Feature-Learning-and-Hash-Coding-with-Deep-Neural-Networks/">Simultaneous Feature Learning and Hash Coding with Deep Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/21/awesome-hash/">awesome-hash</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/09/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%90%86%E8%A7%A3/">最大熵模型的理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/21/Unsupervised-Cross-dataset-Person-Re-identification-by-Transfer-Learning-of-Spatial-Temporal-Pattern/">Unsupervised Cross-dataset Person Re-identification by Transfer Learning of Spatial-Temporal Pattern</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/12/Self-similarity-Grouping-A-Simple-Unsupervised-Cross-Domain-Adaptation-Approach-for-Person-Re-identification/">Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation Approach for Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/">STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/Cross-view-Asymmetric-Metric-Learning-for-Unsupervised-Person-Re-identification/">Cross-view Asymmetric Metric Learning for Unsupervised Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/24/awesome-reid/">awesome-reid</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/">Computer Science</a><span class="category-list-count">17</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/Collections/">Collections</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"><a href="/tags/ReID/" style="font-size: 15px;">ReID</a> <a href="/tags/Unsupervised/" style="font-size: 15px;">Unsupervised</a> <a href="/tags/Cross-view/" style="font-size: 15px;">Cross-view</a> <a href="/tags/Metric-Learning/" style="font-size: 15px;">Metric Learning</a> <a href="/tags/Object-Tracking/" style="font-size: 15px;">Object Tracking</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;"> Deep Hash</a> <a href="/tags/DNN/" style="font-size: 15px;">DNN</a> <a href="/tags/Hard-Negtive-Mining/" style="font-size: 15px;">Hard Negtive Mining</a> <a href="/tags/Hand-Pose-Estimation/" style="font-size: 15px;">Hand Pose Estimation</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Video-Person-ReID/" style="font-size: 15px;">Video Person ReID</a> <a href="/tags/Attention/" style="font-size: 15px;">Attention</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;">Deep Hash</a> <a href="/tags/Grouping/" style="font-size: 15px;">Grouping</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/Unsupervised-ReID/" style="font-size: 15px;">Unsupervised ReID</a> <a href="/tags/Transfer-Learning/" style="font-size: 15px;">Transfer Learning</a> <a href="/tags/hash/" style="font-size: 15px;">hash</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/" style="font-size: 15px;">最大熵</a> <a href="/tags/%E7%86%B5/" style="font-size: 15px;">熵</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archive</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/">2016</a><span class="archive-list-count">7</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Site Map</a> |  <a href="/atom.xml">Subscribe to this site</a> |  <a href="/about/">Contact the blogger</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">weleen.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-101752082-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.4" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>var disqus_shortname = 'https-weleen-github-io';
var disqus_identifier = '2017/06/27/S-U-images-Adversial-Training/';
var disqus_title = 'S+U images Adversial Training';
var disqus_url = 'http://weleen.github.io/2017/06/27/S-U-images-Adversial-Training/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//https-weleen-github-io.disqus.com/count.js" async></script><script type="text/javascript" src="//https-weleen-github-io.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></body></html>