<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="weleen's blog"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification | Welcome to weleen's blog</title><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification</h1><a id="logo" href="/.">Welcome to weleen's blog</a><p class="description">Pursue myself</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="search"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification</h1><div class="post-meta"><a href="/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/#comments" class="comment-count"><i data-disqus-identifier="2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/" class="disqus-comment-count"></i>Guestbook</a><p><span class="date">Sep 10, 2019</span><span><a href="/categories/Computer-Science/" class="category">Computer Science</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Hits</i></i></span></p></div><div class="post-content"><p>AAAI2019 paper</p>
<a id="more"></a>

<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this work, we propose a novel Spatial-Temporal Attention (STA) approach to tackle the large-scale person re-identification task in videos. Different from the most existing methods, which simply compute representations of video clips using frame-level aggregation (e.g. average pooling), the proposed STA adopts a more effective way for producing robust clip-level feature representation. Concretely, our STA fully exploits those discriminative parts of one target person in both spatial and temporal dimensions, which results in a 2-D attention score matrix via inter-frame regularization to measure the importances of spatial parts across different frames. Thus, a more robust clip-level feature representation can be generated according to a weighted sum operation guided by the mined 2-D attention score matrix. In this way, the challenging cases for video-based person re-identification such as pose variation and partial occlusion can be well tackled by the STA. We conduct extensive experiments on two large-scale benchmarks, i.e. MARS and DukeMTMC-VideoReID. In particular, the mAP reaches 87.7% on MARS, which significantly outperforms the state-of-the-arts with a large margin of more than 11.6%.</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>Video Person ReID，给定probe视频（RGB），排序gallery中的视频。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>提出了一个新的网络STA来解决video person re-id问题，文章列举的创新点有：</p>
<p>1）对每个spatial region给予权重，这能够同时做到discriminative part mining和frame selection；<br>相比于AAAI2018的Region-based Quality Estimation Network改进了part-based attention，确实在一定程度更加符合现在reid中使用part level特征。这里是不是可以考虑对part特征的选择进行研究，例如使用deformable或者local的attention？不过这个在特征提取过程中已经做了一部分操作，效果不一定有提升。</p>
<p>2）提出一个inter-frame regularization，用来约束不同帧之间需要不类似。</p>
<p>3）新的特征融合方法。</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115402528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="方法框架"></p>
<p>整体看上去并不复杂，方法总览如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115408134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="方法介绍"></p>
<p>细节上：<br>1、特征提取：<br>ResNet50的最后一层的stride需要调整成1</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115446461.png" alt="在这里插入图片描述"><br>这里公式有点问题，文字意思是先对每个point求特征向量的norm的平方，而后在spatial上面做L2 normalization。之后做的L1 normalization和公式也对不上，公式上只是算了每个spatial block的l1 norm。</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115450699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在得到了每个spatial block的attention score之后，对相同spatial region的score做l1 normalization。</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115456594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>2、regularization的公式，应用在上，注意正则化项只是随机取了两帧计算的，公式在后面。</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115501485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>3、特征融合</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115505529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>使用highest score得到的第一个feature map，使用attention score加权得到第二个feature map，然后使用global average pooling和fc得到最后的特征。</p>
<p>4、算法表</p>
<p><img src="https://img-blog.csdnimg.cn/20190514115508559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>算法表更清晰，但是有一些小错误。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://img-blog.csdnimg.cn/20190514115613819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lpbWluZ1d1MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从ablation study看出提出的component： STA，Fusion，Reg都能提高结果。</p>
</div><div class="post-copyright"><blockquote><p>Original author: weleen</p><p>Original link: <a href="http://weleen.github.io/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/">http://weleen.github.io/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/</a></p><p>Copyright Notice: Please indicate the source of the reprint (must retain the author's signature and link)</p></blockquote></div><div class="tags"><a href="/tags/Video-Person-ReID/">Video Person ReID</a><a href="/tags/Attention/">Attention</a></div><div class="post-share"><div class="social-share"><span>Share:</span></div></div><div class="post-nav"><a href="/2019/09/12/Self-similarity-Grouping-A-Simple-Unsupervised-Cross-Domain-Adaptation-Approach-for-Person-Re-identification/" class="pre">Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation Approach for Person Re-identification</a><a href="/2019/09/10/Cross-view-Asymmetric-Metric-Learning-for-Unsupervised-Person-Re-identification/" class="next">Cross-view Asymmetric Metric Learning for Unsupervised Person Re-identification</a></div><div id="comments"><div id="disqus_thread"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Contents</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#问题"><span class="toc-text">问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结果"><span class="toc-text">结果</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/11/26/Bit-Scalable-Deep-Hashing-With-Regularized-Similarity-Learning-for-Image-Retrieval-and-Person-Re-Identification/">Bit-Scalable Deep Hashing With Regularized Similarity Learning for Image Retrieval and Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Supervised-Hashing-for-Image-Retrieval-via-Image-Representation-Learning/">Supervised Hashing for Image Retrieval via Image Representation Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/Simultaneous-Feature-Learning-and-Hash-Coding-with-Deep-Neural-Networks/">Simultaneous Feature Learning and Hash Coding with Deep Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/21/awesome-hash/">awesome-hash</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/09/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%90%86%E8%A7%A3/">最大熵模型的理解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/21/Unsupervised-Cross-dataset-Person-Re-identification-by-Transfer-Learning-of-Spatial-Temporal-Pattern/">Unsupervised Cross-dataset Person Re-identification by Transfer Learning of Spatial-Temporal Pattern</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/12/Self-similarity-Grouping-A-Simple-Unsupervised-Cross-Domain-Adaptation-Approach-for-Person-Re-identification/">Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation Approach for Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/">STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/10/Cross-view-Asymmetric-Metric-Learning-for-Unsupervised-Person-Re-identification/">Cross-view Asymmetric Metric Learning for Unsupervised Person Re-identification</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/24/awesome-reid/">awesome-reid</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/">Computer Science</a><span class="category-list-count">17</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Science/Collections/">Collections</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"><a href="/tags/ReID/" style="font-size: 15px;">ReID</a> <a href="/tags/Unsupervised/" style="font-size: 15px;">Unsupervised</a> <a href="/tags/Cross-view/" style="font-size: 15px;">Cross-view</a> <a href="/tags/Metric-Learning/" style="font-size: 15px;">Metric Learning</a> <a href="/tags/Object-Tracking/" style="font-size: 15px;">Object Tracking</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;"> Deep Hash</a> <a href="/tags/DNN/" style="font-size: 15px;">DNN</a> <a href="/tags/Hard-Negtive-Mining/" style="font-size: 15px;">Hard Negtive Mining</a> <a href="/tags/Hand-Pose-Estimation/" style="font-size: 15px;">Hand Pose Estimation</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Video-Person-ReID/" style="font-size: 15px;">Video Person ReID</a> <a href="/tags/Attention/" style="font-size: 15px;">Attention</a> <a href="/tags/Deep-Hash/" style="font-size: 15px;">Deep Hash</a> <a href="/tags/Grouping/" style="font-size: 15px;">Grouping</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/Unsupervised-ReID/" style="font-size: 15px;">Unsupervised ReID</a> <a href="/tags/Transfer-Learning/" style="font-size: 15px;">Transfer Learning</a> <a href="/tags/hash/" style="font-size: 15px;">hash</a> <a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 15px;">概率论</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5/" style="font-size: 15px;">最大熵</a> <a href="/tags/%E7%86%B5/" style="font-size: 15px;">熵</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archive</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/">2016</a><span class="archive-list-count">7</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Site Map</a> |  <a href="/atom.xml">Subscribe to this site</a> |  <a href="/about/">Contact the blogger</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">weleen.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-101752082-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.4" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>var disqus_shortname = 'https-weleen-github-io';
var disqus_identifier = '2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/';
var disqus_title = 'STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification';
var disqus_url = 'http://weleen.github.io/2019/09/10/STA-Spatial-Temporal-Attention-for-Large-Scale-Video-based-Person-Re-Identification/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//https-weleen-github-io.disqus.com/count.js" async></script><script type="text/javascript" src="//https-weleen-github-io.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></body></html>